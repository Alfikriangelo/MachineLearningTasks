{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alfikriangelo/MachineLearningTasks/blob/main/10thWeekTask/RegressionMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "TA07j4Gxii4f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.impute import KNNImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "BOHrSJ6hkUZQ"
      },
      "outputs": [],
      "source": [
        "# Definisikan MLP untuk regresi\n",
        "class MLPRegression(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, activation_function):\n",
        "        super(MLPRegression, self).__init__()\n",
        "\n",
        "        # Daftar untuk layer-layer MLP\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev_size, h))\n",
        "            if activation_function == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation_function == 'sigmoid':\n",
        "                layers.append(nn.Sigmoid())\n",
        "            elif activation_function == 'tanh':\n",
        "                layers.append(nn.Tanh())\n",
        "            elif activation_function == 'softmax':\n",
        "                layers.append(nn.Softmax(dim=1))\n",
        "            prev_size = h\n",
        "        layers.append(nn.Linear(prev_size, 1))  # Output layer\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "PAkxXQE5qgOF"
      },
      "outputs": [],
      "source": [
        "# Load dan preprocess data\n",
        "dataset = pd.read_csv(\"sample_data/beijing-pm25.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73ltLYOKqvJG",
        "outputId": "1d789e14-cf76-438b-fc22-548b9cefa76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah missing value di setiap kolom:\n",
            "No          0\n",
            "year        0\n",
            "month       0\n",
            "day         0\n",
            "hour        0\n",
            "pm2.5    2067\n",
            "DEWP        0\n",
            "TEMP        0\n",
            "PRES        0\n",
            "cbwd        0\n",
            "Iws         0\n",
            "Is          0\n",
            "Ir          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Melihat missing values\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(\"Jumlah missing value di setiap kolom:\")\n",
        "print(missing_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "VK8oPRblqxq-"
      },
      "outputs": [],
      "source": [
        "# Mengisi missing values pada kolom 'pm2.5' menggunakan KNN Imputer\n",
        "imputer = KNNImputer(n_neighbors=3, weights='uniform')\n",
        "dataset[['pm2.5']] = imputer.fit_transform(dataset[['pm2.5']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUYqZ4MSqzR2",
        "outputId": "f43c682f-351d-42d1-8b7a-d7bf017b1abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah missing value di setiap kolom:\n",
            "No       0\n",
            "year     0\n",
            "month    0\n",
            "day      0\n",
            "hour     0\n",
            "pm2.5    0\n",
            "DEWP     0\n",
            "TEMP     0\n",
            "PRES     0\n",
            "cbwd     0\n",
            "Iws      0\n",
            "Is       0\n",
            "Ir       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Memastikan bahwa missing value sudah diisi\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(\"Jumlah missing value di setiap kolom:\")\n",
        "print(missing_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "K1cjK8Ynq7Wx"
      },
      "outputs": [],
      "source": [
        "# Memilih fitur dan target\n",
        "X = dataset[['year', 'month', 'day', 'hour', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']].values\n",
        "y = dataset['pm2.5'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "gdYBJdpTq8-p"
      },
      "outputs": [],
      "source": [
        "# Normalisasi fitur\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "TyUYZrRNq_gd"
      },
      "outputs": [],
      "source": [
        "# Split data menjadi train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ZBWKyMBWrCBr"
      },
      "outputs": [],
      "source": [
        "# Konversi ke tensor\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "yQnJFnXUrD7G"
      },
      "outputs": [],
      "source": [
        "# Daftar parameter yang akan dicoba\n",
        "hidden_layers_options = [\n",
        "    (16, 32, 64)\n",
        "]\n",
        "activation_functions = ['relu', 'sigmoid']\n",
        "epochs = [ 100, 250]\n",
        "learning_rates = [ 1,0.1,0.01]\n",
        "batch_sizes = [128,256, 512]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gYP51X3rrEtC"
      },
      "outputs": [],
      "source": [
        "# Hasil eksperimen\n",
        "results = []\n",
        "iteration = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie6npjHErKSn",
        "outputId": "c758d8f3-4635-4b7d-f977-1a77498d3f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=1, batch_size=128\n",
            "Iteration 2: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=1, batch_size=256\n",
            "Iteration 3: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=1, batch_size=512\n",
            "Iteration 4: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=0.1, batch_size=128\n",
            "Iteration 5: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=0.1, batch_size=256\n",
            "Iteration 6: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=0.1, batch_size=512\n",
            "Iteration 7: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=0.01, batch_size=128\n",
            "Iteration 8: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=0.01, batch_size=256\n",
            "Iteration 9: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=100, lr=0.01, batch_size=512\n",
            "Iteration 10: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=1, batch_size=128\n",
            "Iteration 11: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=1, batch_size=256\n",
            "Iteration 12: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=1, batch_size=512\n",
            "Iteration 13: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=0.1, batch_size=128\n",
            "Iteration 14: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=0.1, batch_size=256\n",
            "Iteration 15: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=0.1, batch_size=512\n",
            "Iteration 16: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=0.01, batch_size=128\n",
            "Iteration 17: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=0.01, batch_size=256\n",
            "Iteration 18: Training with hidden_layers=(16, 32, 64), activation_function=relu, epoch=250, lr=0.01, batch_size=512\n",
            "Iteration 19: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=1, batch_size=128\n",
            "Iteration 20: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=1, batch_size=256\n",
            "Iteration 21: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=1, batch_size=512\n",
            "Iteration 22: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=0.1, batch_size=128\n",
            "Iteration 23: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=0.1, batch_size=256\n",
            "Iteration 24: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=0.1, batch_size=512\n",
            "Iteration 25: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=0.01, batch_size=128\n",
            "Iteration 26: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=0.01, batch_size=256\n",
            "Iteration 27: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=100, lr=0.01, batch_size=512\n",
            "Iteration 28: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=1, batch_size=128\n",
            "Iteration 29: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=1, batch_size=256\n",
            "Iteration 30: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=1, batch_size=512\n",
            "Iteration 31: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=0.1, batch_size=128\n",
            "Iteration 32: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=0.1, batch_size=256\n",
            "Iteration 33: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=0.1, batch_size=512\n",
            "Iteration 34: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=0.01, batch_size=128\n",
            "Iteration 35: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=0.01, batch_size=256\n",
            "Iteration 36: Training with hidden_layers=(16, 32, 64), activation_function=sigmoid, epoch=250, lr=0.01, batch_size=512\n"
          ]
        }
      ],
      "source": [
        "# Loop untuk mencocokkan semua kombinasi\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    for activation_function in activation_functions:\n",
        "        for epoch in epochs:\n",
        "            for lr in learning_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    print(f\"Iteration {iteration}: Training with hidden_layers={hidden_layers}, activation_function={activation_function}, epoch={epoch}, lr={lr}, batch_size={batch_size}\")\n",
        "                    iteration += 1\n",
        "\n",
        "                    # Membuat model\n",
        "                    model = MLPRegression(X_train.shape[1], hidden_layers, activation_function)\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "                    criterion = nn.MSELoss()\n",
        "\n",
        "                    # Train model\n",
        "                    model.train()\n",
        "                    for e in range(epoch):\n",
        "                        for i in range(0, len(X_train_tensor), batch_size):\n",
        "                            # Batch slicing\n",
        "                            inputs = X_train_tensor[i:i+batch_size]\n",
        "                            targets = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "                            # Forward pass\n",
        "                            optimizer.zero_grad()\n",
        "                            outputs = model(inputs)\n",
        "                            loss = criterion(outputs, targets)\n",
        "\n",
        "                            # Backward pass and optimization\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # Evaluasi model\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        test_predictions = model(X_test_tensor).numpy()\n",
        "                        y_test_actual = y_test_tensor.numpy()\n",
        "\n",
        "                    # Menghitung R2 dan MSE\n",
        "                    r2 = r2_score(y_test_actual, test_predictions)\n",
        "                    mse = mean_squared_error(y_test_actual, test_predictions)\n",
        "\n",
        "                    # Menyimpan hasil\n",
        "                    results.append({\n",
        "                        'hidden_layers': hidden_layers,\n",
        "                        'activation_function': activation_function,\n",
        "                        'epoch': epoch,\n",
        "                        'learning_rate': lr,\n",
        "                        'batch_size': batch_size,\n",
        "                        'R2': r2,\n",
        "                        'MSE': mse\n",
        "                    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMt8jEshrLxa",
        "outputId": "0884ea92-a937-4f14-d17d-bbe9b7dd657d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   hidden_layers activation_function  epoch  learning_rate  batch_size  \\\n",
            "0   (16, 32, 64)                relu    100           1.00         128   \n",
            "1   (16, 32, 64)                relu    100           1.00         256   \n",
            "2   (16, 32, 64)                relu    100           1.00         512   \n",
            "3   (16, 32, 64)                relu    100           0.10         128   \n",
            "4   (16, 32, 64)                relu    100           0.10         256   \n",
            "5   (16, 32, 64)                relu    100           0.10         512   \n",
            "6   (16, 32, 64)                relu    100           0.01         128   \n",
            "7   (16, 32, 64)                relu    100           0.01         256   \n",
            "8   (16, 32, 64)                relu    100           0.01         512   \n",
            "9   (16, 32, 64)                relu    250           1.00         128   \n",
            "10  (16, 32, 64)                relu    250           1.00         256   \n",
            "11  (16, 32, 64)                relu    250           1.00         512   \n",
            "12  (16, 32, 64)                relu    250           0.10         128   \n",
            "13  (16, 32, 64)                relu    250           0.10         256   \n",
            "14  (16, 32, 64)                relu    250           0.10         512   \n",
            "15  (16, 32, 64)                relu    250           0.01         128   \n",
            "16  (16, 32, 64)                relu    250           0.01         256   \n",
            "17  (16, 32, 64)                relu    250           0.01         512   \n",
            "18  (16, 32, 64)             sigmoid    100           1.00         128   \n",
            "19  (16, 32, 64)             sigmoid    100           1.00         256   \n",
            "20  (16, 32, 64)             sigmoid    100           1.00         512   \n",
            "21  (16, 32, 64)             sigmoid    100           0.10         128   \n",
            "22  (16, 32, 64)             sigmoid    100           0.10         256   \n",
            "23  (16, 32, 64)             sigmoid    100           0.10         512   \n",
            "24  (16, 32, 64)             sigmoid    100           0.01         128   \n",
            "25  (16, 32, 64)             sigmoid    100           0.01         256   \n",
            "26  (16, 32, 64)             sigmoid    100           0.01         512   \n",
            "27  (16, 32, 64)             sigmoid    250           1.00         128   \n",
            "28  (16, 32, 64)             sigmoid    250           1.00         256   \n",
            "29  (16, 32, 64)             sigmoid    250           1.00         512   \n",
            "30  (16, 32, 64)             sigmoid    250           0.10         128   \n",
            "31  (16, 32, 64)             sigmoid    250           0.10         256   \n",
            "32  (16, 32, 64)             sigmoid    250           0.10         512   \n",
            "33  (16, 32, 64)             sigmoid    250           0.01         128   \n",
            "34  (16, 32, 64)             sigmoid    250           0.01         256   \n",
            "35  (16, 32, 64)             sigmoid    250           0.01         512   \n",
            "\n",
            "              R2          MSE  \n",
            "0  -3.248453e-04  7940.767090  \n",
            "1  -4.768372e-07  7938.192383  \n",
            "2  -5.087495e-03  7978.573730  \n",
            "3   5.226849e-01  3789.016846  \n",
            "4   5.601327e-01  3491.749512  \n",
            "5   5.526069e-01  3551.490479  \n",
            "6   5.885657e-01  3266.042969  \n",
            "7   5.891495e-01  3261.408936  \n",
            "8   6.119967e-01  3080.043945  \n",
            "9  -3.248453e-04  7940.767090  \n",
            "10 -9.536743e-07  7938.195801  \n",
            "11 -3.243685e-04  7940.763672  \n",
            "12  5.378835e-01  3668.368164  \n",
            "13  4.985198e-01  3980.844727  \n",
            "14  6.024934e-01  3155.482422  \n",
            "15  6.941538e-01  2427.865234  \n",
            "16  6.549226e-01  2739.289795  \n",
            "17  6.277667e-01  2954.857666  \n",
            "18 -2.306211e-02  8121.260254  \n",
            "19 -9.227276e-03  8011.436523  \n",
            "20 -5.071759e-03  7978.449707  \n",
            "21  5.059978e-01  3921.483154  \n",
            "22 -5.272627e-04  7942.374512  \n",
            "23 -2.063751e-03  7954.571289  \n",
            "24  5.667421e-01  3439.282959  \n",
            "25  5.446838e-01  3614.385986  \n",
            "26  5.472962e-01  3593.647949  \n",
            "27 -2.210653e-02  8113.674805  \n",
            "28 -9.227276e-03  8011.436523  \n",
            "29 -8.471489e-03  8005.437012  \n",
            "30 -4.792213e-05  7938.569336  \n",
            "31 -2.408028e-04  7940.100098  \n",
            "32 -1.892567e-03  7953.211914  \n",
            "33  6.828505e-01  2517.593018  \n",
            "34  6.292073e-01  2943.422607  \n",
            "35  5.936339e-01  3225.810791  \n"
          ]
        }
      ],
      "source": [
        "# Menampilkan hasil eksperimen\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best configuration\n",
        "best_config = max(results, key=lambda x: x['R2'])\n",
        "print(\"Best Configuration:\", best_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiguOmXB6nzz",
        "outputId": "a07d78b9-17e2-43e9-d8e1-5e72df80f0af"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Configuration: {'hidden_layers': (16, 32, 64), 'activation_function': 'relu', 'epoch': 250, 'learning_rate': 0.01, 'batch_size': 128, 'R2': 0.6941537857055664, 'MSE': 2427.8652}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpHMZhPzHmxwix2GvgQxRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}